{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "colab_type": "code",
        "id": "Dkma-q8p3eaz",
        "outputId": "ae8e1a5b-666a-4df3-9d1a-198f59962728"
      },
      "outputs": [],
      "source": [
        "# Boston Housing with a Hidden Layer\n",
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Import keras so that we can access the Boston housing data\n",
        "from tensorflow import keras\n",
        "\n",
        "## Parameters\n",
        "num_epochs = 5000\n",
        "max_num_hidden = 2\n",
        "# base eta value\n",
        "eta = 0.05\n",
        "\n",
        "## Functions\n",
        "def UniformRandomMatrix (rows, cols):\n",
        "    res = [[np.random.uniform () for c in range (cols)] for r in range (rows)]\n",
        "    return np.matrix (res)\n",
        "\n",
        "## Load the data\n",
        "dataset = keras.datasets.boston_housing\n",
        "(train_X, train_y), (_,_) = dataset.load_data (test_split = 0)\n",
        "train_X = np.matrix (train_X)\n",
        "train_y = np.matrix (train_y)\n",
        "(num_samples, num_inputs) = train_X.shape\n",
        "# Add bias\n",
        "bias = np.ones (num_samples)\n",
        "bias = np.matrix (bias).transpose ()\n",
        "train_X = np.append (train_X, bias, axis=1)\n",
        "\n",
        "## Normalize data\n",
        "for i in range (num_inputs):\n",
        "    col = train_X[:,i]\n",
        "    train_X[:,i] = (col - col.mean()) / col.std()\n",
        "miny = train_y.min ()\n",
        "maxy = train_y.max ()\n",
        "mean = (maxy + miny)/2\n",
        "std  = (maxy - miny)/2\n",
        "train_y = (train_y - mean)/std\n",
        "# Adjust for bias column\n",
        "num_inputs += 1\n",
        "# Adjust for sample size\n",
        "eta /= num_samples\n",
        "\n",
        "## Test various hidden node counts\n",
        "for num_hidden in range (1, max_num_hidden + 1):\n",
        "\n",
        "    ## Initialise weights\n",
        "    np.random.seed (123456)\n",
        "    w_hidden = 0.1*UniformRandomMatrix (num_inputs, num_hidden)\n",
        "    w_output = 0.1*UniformRandomMatrix (num_hidden+1, 1)\n",
        "\n",
        "    ## Iterate\n",
        "    mse = []\n",
        "    for _ in range (num_epochs):\n",
        "        # Outputs\n",
        "        phi = np.append (bias, np.tanh (train_X*w_hidden), axis=1)\n",
        "        y = phi * w_output\n",
        "        err = y - train_y.transpose ()\n",
        "        # Gradients\n",
        "        g_output = phi.transpose() * err\n",
        "        phi_range = np.array (phi [:, range (1, num_hidden+1)])\n",
        "        w_output_range = w_output [range (1, num_hidden+1), 0].transpose()\n",
        "        err_term = np.array (err*w_output_range)\n",
        "        g_hidden = train_X.transpose() * np.matrix((1 - phi_range**2)*err_term)\n",
        "        # Update weights\n",
        "        w_output -= eta * g_output\n",
        "        w_hidden -= eta * g_hidden\n",
        "        mse.append (err.var ())\n",
        "\n",
        "    ## Plot\n",
        "    plt.plot (range (num_epochs), mse, label=\"Hidden Neurons = {0}\".format (num_hidden))\n",
        "\n",
        "plt.legend ()\n",
        "plt.show ()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOlX1tooq0XY8iib5VERoio",
      "include_colab_link": true,
      "name": "Boston_Hidden_Layer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
